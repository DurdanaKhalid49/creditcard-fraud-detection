import joblib
import numpy as np
import pandas as pd

# Load the trained model pipeline
model = joblib.load("model/xgb_fraud_pipeline.joblib")

# Column order expected by the model
features = ['Time', 'V1', 'V3', 'V4', 'V5', 'V7', 'V8', 'V10', 'V11', 'V12',
            'V13', 'V16', 'V17', 'V18', 'V19', 'V22', 'V24', 'V26', 'Amount']

# ------------------------------
# 10 FRAUD-LIKE SAMPLES
# ------------------------------
fraud_samples = [
    [20000, -3.5, -4.1, 2.0, -1.8, -2.5, 2.3, -3.2, 2.1, -4.0, 2.9, -1.5, 1.7, -2.2, 3.5, -3.9, 2.2, -4.5, 150.00],
    [25000, -2.9, -3.5, 2.7, -2.3, -2.0, 2.8, -2.7, 2.0, -3.8, 2.5, -1.2, 1.9, -2.6, 3.0, -4.1, 2.1, -4.2, 199.99],
    [30000, -4.2, -3.9, 2.3, -1.6, -2.1, 3.0, -3.0, 2.3, -4.4, 2.2, -1.0, 2.0, -2.0, 3.9, -4.0, 1.9, -4.8, 289.00],
    [10000, -5.0, -4.4, 2.5, -2.2, -3.0, 2.7, -3.3, 2.2, -3.5, 3.2, -1.3, 2.1, -2.1, 4.0, -4.7, 2.5, -4.3, 320.00],
    [40000, -3.3, -3.2, 1.9, -1.9, -2.7, 2.6, -3.1, 2.0, -3.7, 2.6, -1.1, 1.8, -2.3, 3.3, -4.2, 2.3, -4.6, 220.00],
    [11000, -3.9, -4.0, 2.4, -1.4, -2.9, 3.1, -3.5, 2.4, -4.1, 2.7, -1.6, 1.6, -2.5, 3.8, -4.3, 2.4, -4.4, 310.00],
    [15000, -4.5, -4.2, 2.1, -1.7, -2.4, 2.5, -3.6, 2.6, -3.6, 2.3, -1.4, 1.5, -2.7, 3.2, -4.5, 2.0, -4.1, 275.00],
    [8000, -3.6, -3.6, 2.2, -2.0, -2.2, 2.4, -3.4, 2.7, -3.9, 2.8, -1.7, 1.3, -2.8, 3.1, -4.6, 2.6, -4.7, 190.00],
    [6000, -4.1, -4.3, 2.6, -1.5, -2.6, 2.9, -2.9, 2.5, -3.2, 3.0, -1.8, 1.4, -2.4, 3.6, -3.8, 2.8, -4.9, 330.00],
    [9000, -3.7, -3.8, 2.8, -2.1, -2.8, 2.2, -3.7, 2.8, -3.1, 2.4, -1.9, 1.2, -2.9, 3.7, -3.6, 2.7, -4.0, 310.00],
]

# ------------------------------
# 3 NON-FRAUD SAMPLES
# ------------------------------
non_fraud_samples = [
    [100, 1.2, 0.5, -0.6, 0.3, 0.2, -0.4, 0.7, -0.3, 0.4, -0.1, 0.6, -0.7, 0.2, -0.5, 0.1, -0.2, 0.3, 25.00],
    [1200, 0.1, 0.2, -0.3, 0.1, 0.3, -0.2, 0.5, -0.1, 0.3, 0.0, 0.4, -0.5, 0.1, -0.4, 0.2, -0.3, 0.4, 40.00],
    [5000, 0.3, 0.1, -0.2, 0.2, 0.4, -0.3, 0.6, -0.2, 0.5, -0.2, 0.7, -0.6, 0.3, -0.6, 0.3, -0.1, 0.2, 60.00],
]

# Combine all samples
all_samples = fraud_samples + non_fraud_samples
labels = ['Fraud'] * len(fraud_samples) + ['Non-Fraud'] * len(non_fraud_samples)

# Run predictions
print("\nðŸ“Š Testing Samples:\n" + "-"*50)
for idx, sample in enumerate(all_samples):
    X_test = pd.DataFrame([sample], columns=features)
    prediction = model.predict(X_test)[0]
    probability = model.predict_proba(X_test)[0][1]

    expected = labels[idx]
    result = "ðŸš¨ Fraud" if prediction == 1 else "âœ… Safe"
    print(f"Sample #{idx+1} ({expected}) âž¤ Prediction: {result} | Fraud Probability: {probability:.4f}")
